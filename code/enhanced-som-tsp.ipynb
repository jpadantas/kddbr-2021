{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf59c8c3",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5455765-d3f8-4ca5-b105-1290e71feba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sys import argv\n",
    "import pytz\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453015f8",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d09620-136d-4e82-aa53-1e28b80cd1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_closest(candidates, origin):\n",
    "    \"\"\"Return the index of the closest candidate to a given point.\"\"\"\n",
    "    return euclidean_distance(candidates, origin).argmin()\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Return the array of distances of two numpy arrays of points.\"\"\"\n",
    "    return np.linalg.norm(a - b, axis=1)\n",
    "\n",
    "def route_distance(cities):\n",
    "    \"\"\"Return the cost of traversing a route of cities in a certain order.\"\"\"\n",
    "    points = cities[['x', 'y']]\n",
    "    distances = euclidean_distance(points, np.roll(points, 1, axis=0))\n",
    "    return np.sum(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68988a",
   "metadata": {},
   "source": [
    "### Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0134e004-9f90-4989-9900-07bcb9f18d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network(size):\n",
    "    \"\"\"\n",
    "    Generate a neuron network of a given size.\n",
    "\n",
    "    Return a vector of two dimensional points in the interval [0,1].\n",
    "    \"\"\"\n",
    "    return np.random.rand(size, 2)\n",
    "\n",
    "def get_neighborhood(center, radix, domain):\n",
    "    \"\"\"Get the range gaussian of given radix around a center index.\"\"\"\n",
    "\n",
    "    # Impose an upper bound on the radix to prevent NaN and blocks\n",
    "    if radix < 1:\n",
    "        radix = 1\n",
    "\n",
    "    # Compute the circular network distance to the center\n",
    "    deltas = np.absolute(center - np.arange(domain))\n",
    "    distances = np.minimum(deltas, domain - deltas)\n",
    "\n",
    "    # Compute Gaussian distribution around the given center\n",
    "    return np.exp(-(distances*distances) / (2*(radix*radix)))\n",
    "\n",
    "def get_route(cities, network):\n",
    "    \"\"\"Return the route computed by a network.\"\"\"\n",
    "    cities['winner'] = cities[['x', 'y']].apply(\n",
    "        lambda c: select_closest(network, c),\n",
    "        axis=1, raw=True)\n",
    "\n",
    "    return cities.sort_values('winner').index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe26e4",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5511e1-aa71-47de-85c3-39932c06d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsp(filename):\n",
    "    \"\"\"\n",
    "    Read a file in .tsp format into a pandas DataFrame\n",
    "\n",
    "    The .tsp files can be found in the TSPLIB project. Currently, the library\n",
    "    only considers the possibility of a 2D map.\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        node_coord_start = None\n",
    "        dimension = None\n",
    "        lines = f.readlines()\n",
    "\n",
    "        # Obtain the information about the .tsp\n",
    "        i = 0\n",
    "        while not dimension or not node_coord_start:\n",
    "            line = lines[i]\n",
    "            if line.startswith('DIMENSION :'):\n",
    "                dimension = int(line.split()[-1])\n",
    "            if line.startswith('NODE_COORD_SECTION'):\n",
    "                node_coord_start = i\n",
    "            i = i+1\n",
    "\n",
    "        #print('Problem with {} cities read.'.format(dimension))\n",
    "\n",
    "        f.seek(0)\n",
    "\n",
    "        # Read a data frame out of the file descriptor\n",
    "        cities = pd.read_csv(\n",
    "            f,\n",
    "            skiprows=node_coord_start + 1,\n",
    "            sep=' ',\n",
    "            names=['city', 'y', 'x'],\n",
    "            dtype={'city': str, 'x': np.float64, 'y': np.float64},\n",
    "            header=None,\n",
    "            nrows=dimension\n",
    "        )\n",
    "\n",
    "        # cities.set_index('city', inplace=True)\n",
    "\n",
    "        return cities\n",
    "\n",
    "def normalize(points):\n",
    "    \"\"\"\n",
    "    Return the normalized version of a given vector of points.\n",
    "\n",
    "    For a given array of n-dimensions, normalize each dimension by removing the\n",
    "    initial offset and normalizing the points in a proportional interval: [0,1]\n",
    "    on y, maintining the original ratio on x.\n",
    "    \"\"\"\n",
    "    ratio = (points.x.max() - points.x.min()) / (points.y.max() - points.y.min()), 1\n",
    "    ratio = np.array(ratio) / max(ratio)\n",
    "    norm = points.apply(lambda c: (c - c.min()) / (c.max() - c.min()))\n",
    "    return norm.apply(lambda p: ratio * p, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692e85f",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35a5a7e-dce7-4488-a019-3f23ce9c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(cities, neurons, name='diagram.png', ax=None):\n",
    "    \"\"\"Plot a graphical representation of the problem\"\"\"\n",
    "    mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=(5, 5), frameon = False)\n",
    "        axis = fig.add_axes([0,0,1,1])\n",
    "\n",
    "        axis.set_aspect('equal', adjustable='datalim')\n",
    "        plt.axis('off')\n",
    "\n",
    "        axis.scatter(cities['x'], cities['y'], color='red', s=4)\n",
    "        axis.plot(neurons[:,0], neurons[:,1], ls='-', color='#0063ba', markersize=2)\n",
    "\n",
    "        plt.savefig(name, bbox_inches='tight', pad_inches=0, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    else:\n",
    "        ax.scatter(cities['x'], cities['y'], color='red', s=4)\n",
    "        ax.plot(neurons[:,0], neurons[:,1], ls='-', color='#0063ba', markersize=2)\n",
    "        return ax\n",
    "\n",
    "def plot_route(cities, route, name='diagram.png', ax=None):\n",
    "    \"\"\"Plot a graphical representation of the route obtained\"\"\"\n",
    "    mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "    if not ax:\n",
    "        fig = plt.figure(figsize=(5, 5), frameon = False)\n",
    "        axis = fig.add_axes([0,0,1,1])\n",
    "\n",
    "        axis.set_aspect('equal', adjustable='datalim')\n",
    "        plt.axis('off')\n",
    "\n",
    "        axis.scatter(cities['x'], cities['y'], color='red', s=4)\n",
    "        route = cities.reindex(route)\n",
    "        route.loc[route.shape[0]] = route.iloc[0]\n",
    "        axis.plot(route['x'], route['y'], color='purple', linewidth=1)\n",
    "\n",
    "        plt.savefig(name, bbox_inches='tight', pad_inches=0, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    else:\n",
    "        ax.scatter(cities['x'], cities['y'], color='red', s=4)\n",
    "        route = cities.reindex(route)\n",
    "        route.loc[route.shape[0]] = route.iloc[0]\n",
    "        ax.plot(route['x'], route['y'], color='purple', linewidth=1)\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d722894",
   "metadata": {},
   "source": [
    "### SOM Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e926997-15fd-4894-af3e-d03ab7211e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def som_random(problem, iterations, learning_rate=0.8):\n",
    "    \"\"\"Solve the TSP using a Self-Organizing Map.\"\"\"\n",
    "\n",
    "    # Obtain the normalized set of cities (w/ coord in [0,1])\n",
    "    cities = problem.copy()\n",
    "    \n",
    "    cities[['x', 'y']] = normalize(cities[['x', 'y']])\n",
    "\n",
    "    # The population size is 8 times the number of cities\n",
    "    n = cities.shape[0] * 6\n",
    "\n",
    "    # Generate an adequate network of neurons:\n",
    "    network = generate_network(n)\n",
    "    #print('Network of {} neurons created. Starting the iterations:'.format(n))\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        if not i % 100:\n",
    "            #pass\n",
    "            print('\\t> Iteration {}/{}'.format(i, iterations), end=\"\\r\")\n",
    "                \n",
    "        # Choose a random city\n",
    "        city = cities.sample(1)[['x', 'y']].values\n",
    "        #city = find_further(cities)\n",
    "\n",
    "        winner_idx = select_closest(network, city)\n",
    "\n",
    "\n",
    "        # Generate a filter that applies changes to the winner's gaussian\n",
    "        gaussian = get_neighborhood(winner_idx, n//10, network.shape[0])\n",
    "        # Update the network's weights (closer to the city)\n",
    "        network += gaussian[:,np.newaxis] * learning_rate * (city - network)\n",
    "        # Decay the variables\n",
    "        learning_rate = learning_rate * 0.99997\n",
    "        n = n * 0.9997\n",
    "\n",
    "        path = '../'\n",
    "\n",
    "        # Check for plotting interval\n",
    "        if not i % 1000:\n",
    "            plot_network(cities, network, name=path+'diagrams/{:05d}.png'.format(i))\n",
    "\n",
    "        # Check if any parameter has completely decayed.\n",
    "        if n < 1:\n",
    "            print('Radius has completely decayed, finishing execution',\n",
    "            'at {} iterations'.format(i))\n",
    "            break\n",
    "        if learning_rate < 0.001:\n",
    "            print('Learning rate has completely decayed, finishing execution',\n",
    "            'at {} iterations'.format(i))\n",
    "            break\n",
    "    else:\n",
    "        #pass\n",
    "        print('Completed {} iterations.'.format(iterations))\n",
    "\n",
    "    plot_network(cities, network, name=path+'diagrams/final.png')\n",
    "\n",
    "    route = get_route(cities, network)\n",
    "    #print('cities:',cities)\n",
    "    #print('route:', route)\n",
    "    \n",
    "    plot_route(cities, route, path+'diagrams/route.png')\n",
    "    return route"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22c104",
   "metadata": {},
   "source": [
    "#### Defining n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33bdab93-deff-4894-8e60-152206a90fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f50aa6f-2d7a-4aa4-9852-6c6102e20405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdd(k):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(50*k,50*(k+1)):\n",
    "        print(i)\n",
    "        #chamada da função{\n",
    "        problem = read_tsp(f\"../data/input{i+1}.tsp\")\n",
    "        route = som_random(problem, 1000000)\n",
    "\n",
    "        problem = problem.reindex(route)\n",
    "\n",
    "        distance = route_distance(problem)\n",
    "                \n",
    "        #criação do vetor de adjacências\n",
    "        d = pd.DataFrame(np.zeros((1, 40001)))\n",
    "\n",
    "        for j in range(len(route)-1):\n",
    "            d[route[j]*200+route[j+1]+1] = 1\n",
    "            d[route[j+1]*200+route[j]+1] = 1\n",
    "        d[route[-1]*200+route[0]+1] = 1\n",
    "        d[route[0]*200+route[-1]+1] = 1\n",
    "\n",
    "        d[0]=i\n",
    "\n",
    "        df = df.append(d)\n",
    "\n",
    "    columns = []\n",
    "    columns.append('graph')\n",
    "    for i1 in range(200):\n",
    "        for i2 in range(200):\n",
    "            columns.append(f'a_{i1},{i2}')    \n",
    "\n",
    "    df.columns = columns\n",
    "\n",
    "    df = df.astype('int32')\n",
    "\n",
    "    #time = datetime.datetime.now(pytz.timezone('Brazil/East')).strftime(\"%d-%m-%Y_%H:%M\")\n",
    "\n",
    "    df.to_csv( f'../outputs/outputs_13/output_{k}.csv', index=False) \n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f8be5",
   "metadata": {},
   "source": [
    "#### Use parallel to use all processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "763553af-95bf-4da5-a4f2-465f22f29645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done   1 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=40)]: Done   2 out of  40 | elapsed: 41.7min remaining: 792.3min\n",
      "[Parallel(n_jobs=40)]: Done   3 out of  40 | elapsed: 41.8min remaining: 516.0min\n",
      "[Parallel(n_jobs=40)]: Done   4 out of  40 | elapsed: 41.9min remaining: 376.7min\n",
      "[Parallel(n_jobs=40)]: Done   5 out of  40 | elapsed: 42.0min remaining: 293.9min\n",
      "[Parallel(n_jobs=40)]: Done   6 out of  40 | elapsed: 42.0min remaining: 238.1min\n",
      "[Parallel(n_jobs=40)]: Done   7 out of  40 | elapsed: 42.0min remaining: 198.1min\n",
      "[Parallel(n_jobs=40)]: Done   8 out of  40 | elapsed: 42.0min remaining: 168.1min\n",
      "[Parallel(n_jobs=40)]: Done   9 out of  40 | elapsed: 42.1min remaining: 145.0min\n",
      "[Parallel(n_jobs=40)]: Done  10 out of  40 | elapsed: 42.1min remaining: 126.4min\n",
      "[Parallel(n_jobs=40)]: Done  11 out of  40 | elapsed: 42.1min remaining: 111.1min\n",
      "[Parallel(n_jobs=40)]: Done  12 out of  40 | elapsed: 42.2min remaining: 98.4min\n",
      "[Parallel(n_jobs=40)]: Done  13 out of  40 | elapsed: 42.2min remaining: 87.6min\n",
      "[Parallel(n_jobs=40)]: Done  14 out of  40 | elapsed: 42.2min remaining: 78.3min\n",
      "[Parallel(n_jobs=40)]: Done  15 out of  40 | elapsed: 42.2min remaining: 70.4min\n",
      "[Parallel(n_jobs=40)]: Done  16 out of  40 | elapsed: 42.2min remaining: 63.3min\n",
      "[Parallel(n_jobs=40)]: Done  17 out of  40 | elapsed: 42.2min remaining: 57.1min\n",
      "[Parallel(n_jobs=40)]: Done  18 out of  40 | elapsed: 42.2min remaining: 51.6min\n",
      "[Parallel(n_jobs=40)]: Done  19 out of  40 | elapsed: 42.2min remaining: 46.7min\n",
      "[Parallel(n_jobs=40)]: Done  20 out of  40 | elapsed: 42.3min remaining: 42.3min\n",
      "[Parallel(n_jobs=40)]: Done  21 out of  40 | elapsed: 42.3min remaining: 38.3min\n",
      "[Parallel(n_jobs=40)]: Done  22 out of  40 | elapsed: 42.3min remaining: 34.6min\n",
      "[Parallel(n_jobs=40)]: Done  23 out of  40 | elapsed: 42.3min remaining: 31.3min\n",
      "[Parallel(n_jobs=40)]: Done  24 out of  40 | elapsed: 42.3min remaining: 28.2min\n",
      "[Parallel(n_jobs=40)]: Done  25 out of  40 | elapsed: 42.3min remaining: 25.4min\n",
      "[Parallel(n_jobs=40)]: Done  26 out of  40 | elapsed: 42.4min remaining: 22.8min\n",
      "[Parallel(n_jobs=40)]: Done  27 out of  40 | elapsed: 42.4min remaining: 20.4min\n",
      "[Parallel(n_jobs=40)]: Done  28 out of  40 | elapsed: 42.4min remaining: 18.2min\n",
      "[Parallel(n_jobs=40)]: Done  29 out of  40 | elapsed: 42.5min remaining: 16.1min\n",
      "[Parallel(n_jobs=40)]: Done  30 out of  40 | elapsed: 42.5min remaining: 14.2min\n",
      "[Parallel(n_jobs=40)]: Done  31 out of  40 | elapsed: 42.5min remaining: 12.3min\n",
      "[Parallel(n_jobs=40)]: Done  32 out of  40 | elapsed: 42.5min remaining: 10.6min\n",
      "[Parallel(n_jobs=40)]: Done  33 out of  40 | elapsed: 42.5min remaining:  9.0min\n",
      "[Parallel(n_jobs=40)]: Done  34 out of  40 | elapsed: 42.6min remaining:  7.5min\n",
      "[Parallel(n_jobs=40)]: Done  35 out of  40 | elapsed: 42.7min remaining:  6.1min\n",
      "[Parallel(n_jobs=40)]: Done  36 out of  40 | elapsed: 42.7min remaining:  4.7min\n",
      "[Parallel(n_jobs=40)]: Done  37 out of  40 | elapsed: 42.8min remaining:  3.5min\n",
      "[Parallel(n_jobs=40)]: Done  38 out of  40 | elapsed: 42.8min remaining:  2.3min\n",
      "[Parallel(n_jobs=40)]: Done  40 out of  40 | elapsed: 43.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=40)]: Done  40 out of  40 | elapsed: 43.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=n, verbose=100)(delayed(kdd)(i) for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e898c52-7403-4e8f-a8f9-62f352029d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 40001)\n",
      "1\n",
      "(100, 40001)\n",
      "2\n",
      "(150, 40001)\n",
      "3\n",
      "(200, 40001)\n",
      "4\n",
      "(250, 40001)\n",
      "5\n",
      "(300, 40001)\n",
      "6\n",
      "(350, 40001)\n",
      "7\n",
      "(400, 40001)\n",
      "8\n",
      "(450, 40001)\n",
      "9\n",
      "(500, 40001)\n",
      "10\n",
      "(550, 40001)\n",
      "11\n",
      "(600, 40001)\n",
      "12\n",
      "(650, 40001)\n",
      "13\n",
      "(700, 40001)\n",
      "14\n",
      "(750, 40001)\n",
      "15\n",
      "(800, 40001)\n",
      "16\n",
      "(850, 40001)\n",
      "17\n",
      "(900, 40001)\n",
      "18\n",
      "(950, 40001)\n",
      "19\n",
      "(1000, 40001)\n",
      "20\n",
      "(1050, 40001)\n",
      "21\n",
      "(1100, 40001)\n",
      "22\n",
      "(1150, 40001)\n",
      "23\n",
      "(1200, 40001)\n",
      "24\n",
      "(1250, 40001)\n",
      "25\n",
      "(1300, 40001)\n",
      "26\n",
      "(1350, 40001)\n",
      "27\n",
      "(1400, 40001)\n",
      "28\n",
      "(1450, 40001)\n",
      "29\n",
      "(1500, 40001)\n",
      "30\n",
      "(1550, 40001)\n",
      "31\n",
      "(1600, 40001)\n",
      "32\n",
      "(1650, 40001)\n",
      "33\n",
      "(1700, 40001)\n",
      "34\n",
      "(1750, 40001)\n",
      "35\n",
      "(1800, 40001)\n",
      "36\n",
      "(1850, 40001)\n",
      "37\n",
      "(1900, 40001)\n",
      "38\n",
      "(1950, 40001)\n",
      "39\n",
      "(2000, 40001)\n"
     ]
    }
   ],
   "source": [
    "mypath = '../outputs/outputs_13/'\n",
    "\n",
    "df_final = pd.read_csv(f'{mypath}output_0.csv')\n",
    "print(df_final.shape)\n",
    "\n",
    "for i in range(1,n):\n",
    "    print(i)\n",
    "    df = pd.read_csv(f'{mypath}output_{i}.csv')\n",
    "    df_final = pd.concat([df_final,df])\n",
    "    print(df_final.shape)\n",
    "\n",
    "df_final.to_csv( f'{mypath}output_final.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
